{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM for Wildfire Growth Prediction (404 Fire Not Found Team)\n",
    "\n",
    "Basic CNN is based on starter code (provided) to solve the wildfire growth challenge!\n",
    "\n",
    " - Boilerplate provides infrastructure and helper functions to call and process the data.\n",
    " - LSTM integrated by 404 Fire not found team\n",
    " - Other features, tweaks and improvements by team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Paths for data and fires\n",
    "data_path = \"./\"\n",
    "train_path = data_path + \"train/\"\n",
    "test_path = data_path + \"test/\"\n",
    "tr_fnums = [\"fire1209\", \"fire1298\", \"fire1386\", \"fire2034\", \"fire2210\", \"fire2211\", \"fire2212\"]\n",
    "te_fnums = [\"fire2214\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util variables\n",
    "device = 'cuda'\n",
    "target_shape = (528, 720)\n",
    "\n",
    "# Util functions\n",
    "def pad_to_fit(d, shape):\n",
    "    h, w = d.shape\n",
    "    pad_h = shape[0] - h\n",
    "    pad_w = shape[1] - w\n",
    "    if pad_h > 0 or pad_w > 0:\n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "\n",
    "        d = np.pad(d, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    return d\n",
    "\n",
    "def normalize(d):\n",
    "    m = np.mean(d)\n",
    "    s = np.std(d)\n",
    "    return (d - m)/s\n",
    "\n",
    "def tif2np(tif):\n",
    "    with rio.open(tif) as src:\n",
    "        data = src.read(1)  # Read the first band\n",
    "    return pad_to_fit(np.nan_to_num(data, nan=0.0), target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to load data\n",
    "\n",
    "The load fire function loads and processes data for the denoted fire. The fire is then stacked into a numpy array.\n",
    "\n",
    "The load day function loads in a day of data for a specified fire. \n",
    "\n",
    "<ins>**Additional data should be loaded and specified into this function**.<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_day(path, day):\n",
    "    # fire_weather\n",
    "    fwi = path+'/fire_weather/fire_weather_index_day{}.tif'.format(day)\n",
    "    fwi = normalize(tif2np(fwi))\n",
    "    # weather relative humidity\n",
    "    wrh = path+'/weather/noon_relative_humidity_day{}.tif'.format(day)\n",
    "    wrh = normalize(tif2np(wrh))\n",
    "    # weather wind speed\n",
    "    wws = path+'/weather/noon_wind_speed_day{}.tif'.format(day)\n",
    "    wws = normalize(tif2np(wws))\n",
    "    \n",
    "    ## Added by team\n",
    "    # buildup index\n",
    "    bi = path+'/fire_weather/build_up_index_day{}.tif'.format(day)\n",
    "    bi = normalize(tif2np(bi))\n",
    "\n",
    "    # # draught code\n",
    "    # dc = path+'/fire_weather/drought_code_day{}.tif'.format(day)\n",
    "    # dc = normalize(tif2np(dc))\n",
    "\n",
    "    # max temperature\n",
    "    mt = path+'/weather/noon_temperature_day{}.tif'.format(day)\n",
    "    mt = normalize(tif2np(mt))\n",
    "\n",
    "    # relative humidity\n",
    "    rh = path+'/weather/noon_relative_humidity_day{}.tif'.format(day)\n",
    "    rh = normalize(tif2np(rh))\n",
    "\n",
    "    # precipitation\n",
    "    pr = path+'/weather/24hr_accumulated_precipitation_day{}.tif'.format(day)\n",
    "    pr = normalize(tif2np(pr))\n",
    "\n",
    "\n",
    "    return [fwi, wrh, wws, bi, mt, rh, pr]\n",
    "\n",
    "def load_fire(fire_num, split = \"Train\"):\n",
    "    path = train_path + fire_num\n",
    "    if split == \"Test\":\n",
    "        path = test_path + fire_num\n",
    "    \n",
    "    ftif = path + \"/fire/{}.tif\".format(fire_num)\n",
    "    if split == \"Test\":\n",
    "        ftif = path + \"/fire/{}_train.tif\".format(fire_num)\n",
    "    fdata = tif2np(ftif)\n",
    "\n",
    "    minjd, maxjd = int(np.min(fdata[np.nonzero(fdata)])), int(np.max(fdata))\n",
    "    lastjd = maxjd\n",
    "    if split == \"Test\":\n",
    "        maxjd += 21\n",
    "    \n",
    "    elev = normalize(tif2np(path+'/topography/dem.tif'))\n",
    "    slope = normalize(tif2np(path+'/topography/slope.tif'))\n",
    "    fuels = tif2np(path+'/fuels/fbp_fuels.tif')\n",
    "    ignition = tif2np(path+'/fire/ignitions.tif')\n",
    "\n",
    "    dataset = []\n",
    "    gt = ignition\n",
    "    cfire = ignition\n",
    "    for d in range(minjd, maxjd):\n",
    "        data = {}\n",
    "\n",
    "        fuels[cfire != 0] = 0\n",
    "        ft = [fuels]\n",
    "        ft.extend([cfire, gt, slope, elev])\n",
    "        ft.extend(load_day(path, d))\n",
    "        ft = np.stack(ft)\n",
    "        data['ft'] = ft\n",
    "\n",
    "        if d < lastjd:\n",
    "            gt = fdata == float(d)\n",
    "            data['gt'] = gt\n",
    "\n",
    "        cfire = np.logical_or(cfire ,gt)\n",
    "        \n",
    "        dataset.append(data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets and dataloaders\n",
    "\n",
    "<ins>Create/implement data augmentations/transformations here<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2h/60_lymbn6x1f8_pzz2pj35nm0000gn/T/ipykernel_43758/3138354000.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "  return (d - m)/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n",
      "(12, 528, 720)\n",
      "30\n",
      "(12, 528, 720)\n"
     ]
    }
   ],
   "source": [
    "class FireDataset(Dataset):\n",
    "    def __init__(self, split=\"Train\"):\n",
    "        fnums = tr_fnums if split==\"Train\" else te_fnums\n",
    "        self.dataset = []\n",
    "        for fnum in fnums:\n",
    "            self.dataset.extend(load_fire(fnum, split=split))\n",
    "        print(len(self.dataset))\n",
    "        print(self.dataset[0]['ft'].shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "    \n",
    "trainset = FireDataset(split=\"Train\")\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [0.9,0.1])\n",
    "testset = FireDataset(split=\"Test\")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=8, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network/model\n",
    "\n",
    "In this example, we define a simple 2 layer cnn model. \n",
    "\n",
    "<ins>**Modify the model as you see fit!**<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FuelEmbeddings(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(FuelEmbeddings, self).__init__()\n",
    "\n",
    "        unique_values = [0, 1, 2, 3, 4, 7, 13, 31, 101, 425, 635, 650, 665]\n",
    "        self.unique_values = torch.tensor(unique_values).to(device)  # Unique values in the categorical feature\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(unique_values), embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, categorical_feature):\n",
    "        # (B,H,W) -> (B,H,W,U) where U is unique values count\n",
    "        mask = categorical_feature.unsqueeze(-1) == self.unique_values\n",
    "        matching_indices = torch.argmax(mask.int(), dim=-1)\n",
    "\n",
    "        # Apply embedding and reshape\n",
    "        # (B,H,W,U) -> (B,H,W,6) -> (B,6,H,W) in default setting\n",
    "        embedded_fuel = self.embedding(matching_indices)\n",
    "        embedded_reshaped_fuel = embedded_fuel.permute(0, 3, 1, 2)\n",
    "\n",
    "        return embedded_reshaped_fuel\n",
    "\n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self, embedding_dim=6, num_features=8):\n",
    "        super(CNN1, self).__init__()\n",
    "\n",
    "        self.fuelembedding = FuelEmbeddings(embedding_dim)\n",
    "\n",
    "        # (266, 433)\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=(embedding_dim+num_features-1), out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            # nn.Conv2d(in_channels=17, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n",
    "        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n",
    "\n",
    "        # Replace the original categorical feature with the embedded feature\n",
    "        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n",
    "\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        out = self.sigmoid(x)\n",
    "\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss function\n",
    "\n",
    "<ins>**Create/define/specify your own loss function here!**<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super(IoULoss, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        # threshold condition is not differentiable so just use softmaxed data\n",
    "        # Flatten the tensors\n",
    "        outputs = outputs.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        # Compute the intersection\n",
    "        intersection = (outputs * labels).sum()\n",
    "\n",
    "        # Compute the union\n",
    "        union = outputs.sum() + labels.sum() - intersection\n",
    "        iou = intersection / (union + 1e-6)  # Add a small epsilon for numerical stability\n",
    "        loss = 1 - iou\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    total_steps = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        ft = batch['ft'].to(device).float()\n",
    "        gt = batch['gt'].to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(ft).squeeze()\n",
    "\n",
    "        loss = criterion(output, gt)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        total_steps += 1\n",
    "    return running_loss/total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader):\n",
    "    model.eval()\n",
    "    acc = []\n",
    "    iou = []\n",
    "    f1 = []\n",
    "    total_steps = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            ft = batch['ft'].to(device)\n",
    "            gt = torch.flatten(batch['gt'])\n",
    "\n",
    "            output = torch.flatten(model(ft)).squeeze().cpu()\n",
    "            output = (output > 0.5)\n",
    "\n",
    "            acc.append(accuracy_score(gt, output))\n",
    "            iou.append(jaccard_score(gt, output))\n",
    "            f1.append(f1_score(gt, output))\n",
    "            total_steps += 1\n",
    "    return sum(acc)/total_steps, sum(iou)/total_steps, sum(f1)/total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference function\n",
    "\n",
    "Saves the inference results to a submission file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cfire = torch.zeros(target_shape)\n",
    "        for i, day in enumerate(dataloader):\n",
    "            ft = day['ft'].to(device)\n",
    "\n",
    "            # Create the submission file after 10 days\n",
    "            if i > 9:\n",
    "                cfire = torch.logical_or(output, cfire) # define the cumulative fire\n",
    "                ft[0][1] = cfire # set the cumulative fire for the next input\n",
    "                ft[0][2] = output # set the next step fire for the next input\n",
    "            else:\n",
    "                cfire = ft[0][1]\n",
    "\n",
    "            output = model(ft)\n",
    "            output = (output > 0.5)\n",
    "    \n",
    "    # Save the cumulative fire\n",
    "    pred = cfire.cpu().squeeze().numpy()\n",
    "    save_df = pd.DataFrame(pred)  # convert img data to df\n",
    "    # save_df.to_csv(\"./output/submission.csv\", index_label='row')\n",
    "    save_df.to_csv(\"/Users/jromero/Documents/GitHub/watAIhackathon24/submission.csv\", index_label='row') ## NOTE: Change the path to the output folder\n",
    "\n",
    "    return cfire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training/eval/inference loop\n",
    "\n",
    "<ins>**Define new optimizers here**<ins>\n",
    "\n",
    "<ins>**Utilize a scheduler here**<ins>\n",
    "\n",
    "<ins>**Change the learning rate here**<ins>\n",
    "\n",
    "<ins>**Implement a better early stopping strategy here**<ins>\n",
    "\n",
    "<ins>**Implement other tricks here (i.e. EMA)**<ins>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  avg iou loss:nan avg acc: 0.996 avg f1: 0.000 avg iou: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available and move the model to the MPS device\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu') \n",
    "device = torch.device(\"cpu\")\n",
    "## NOTE: Change to 'cuda' if you have a GPU (non apple silicon), also note that MPS may be restricted\n",
    "\n",
    "# device = torch.device(\"cpu\") ## NOTE: Change to 'cuda' if you have a GPU (non apple silicon)\n",
    "model = CNN1(num_features=12)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = IoULoss()\n",
    "epochs = 1\n",
    "best_miou = 0\n",
    "for e in range(epochs):\n",
    "    loss = train(model, trainloader, optimizer, criterion)\n",
    "    aa, miou, mf1 = eval(model,valloader)\n",
    "\n",
    "    if miou > best_miou:\n",
    "        best_miou = miou\n",
    "        cfire, = inference(model, testloader)\n",
    "        e = str(e)+\"*\"\n",
    "    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou: {:.3f}\".format(loss, aa, mf1, miou))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jromero/Documents/GitHub/watAIhackathon24/output/submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the submission file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/jromero/Documents/GitHub/watAIhackathon24/output/submission.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Check data types\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mdtypes)\n",
      "File \u001b[0;32m~/Documents/GitHub/watAIhackathon24/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/watAIhackathon24/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documents/GitHub/watAIhackathon24/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/watAIhackathon24/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/GitHub/watAIhackathon24/venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jromero/Documents/GitHub/watAIhackathon24/output/submission.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the submission file\n",
    "df = pd.read_csv(\"/Users/jromero/Documents/GitHub/watAIhackathon24/output/submission.csv\", index_col=0)\n",
    "\n",
    "# Check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert the DataFrame to numeric, coercing errors\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check for any remaining non-numeric values\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "# If there are NaN values, you can fill them or handle them as needed\n",
    "# For example, filling NaN values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Plot the cumulative fire\n",
    "plt.imshow(df.values, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Ideas to implement!\n",
    "\n",
    "<ins>**Ensemble learning - voting**<ins>\n",
    "\n",
    "<ins>**Implement hot spot data pipeline**<ins>\n",
    "\n",
    "<ins>**Make better use of temporal data**<ins>\n",
    "\n",
    "<ins>**Get creative!**<ins>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
